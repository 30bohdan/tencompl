{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from scipy.optimize import minimize \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aul_f(X, Y, Z, n, m, u, mu, tensor, entries = None):\n",
    "    nx, ny, nz = n\n",
    "    val = 0;\n",
    "    val += np.sum(X**2);\n",
    "    for i in range(m):\n",
    "        val += np.sum(Y[i]**2) * np.sum(Z[i]**2);\n",
    "    \n",
    "    if entries is None:\n",
    "        ten = np.zeros(nx*ny*nz);\n",
    "        for i in range(m):\n",
    "            ten += np.kron(X[i], np.kron(Y[i], Z[i]))\n",
    "        val = val - np.dot(u.T, (ten - tensor));\n",
    "        val = val+np.sum((ten - tensor)**2)*(1/(2*mu));\n",
    "    else:\n",
    "        for xi in entries.keys():\n",
    "            for yi in entries[xi].keys():\n",
    "                for zi in entries[xi][yi]:\n",
    "                    ent = -tensor[xi*ny*nz+nz*yi+zi]\n",
    "                    for j in range(m):\n",
    "                        ent += X[j, xi]*Y[j, yi]*Z[j, zi]\n",
    "                    val += (1/(2*mu))* ent**2;\n",
    "                    \n",
    "    return val;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_aulf(X, n, m, u, mu, tensor, entries = None):\n",
    "    grad = np.zeros(X.shape);\n",
    "    grad[:n*m] = X[:n*m]*2.0;\n",
    "    for i in range(m):\n",
    "        grad[n*m+i*n:n*m+(i+1)*n] = 2*X[n*m+i*n:n*m+(i+1)*n]*np.sum(X[2*n*m+i*n:2*n*m+(i+1)*n]**2);\n",
    "        grad[2*n*m+i*n:2*n*m+(i+1)*n] = 2*X[2*n*m+i*n:2*n*m+(i+1)*n]*np.sum(X[n*m+i*n:n*m+(i+1)*n]**2);\n",
    "    ten = np.zeros(n*n*n);\n",
    "    for i in range(m):\n",
    "        ten += np.kron(X[i*n: (i+1)*n], np.kron(X[n*m+i*n: n*m+(i+1)*n], X[2*n*m+i*n: 2*n*m+(i+1)*n]))\n",
    "    ten = ten - tensor;\n",
    "    ten = (1/mu)*ten - u;\n",
    "    ten1 = ten.reshape(n, n*n)\n",
    "    ten2 = ten1.T.reshape(n, n*n)\n",
    "    ten3 = ten2.T.reshape(n, n*n)\n",
    "    for i in range(m):\n",
    "        grad[i*n:(i+1)*n] += np.dot(ten1, \n",
    "                                     np.kron(X[n*m+i*n: n*m+(i+1)*n], X[2*n*m+i*n: 2*n*m+(i+1)*n]))\n",
    "        grad[n*m+i*n:n*m+(i+1)*n] += np.dot(ten2, \n",
    "                                         np.kron(X[2*n*m+i*n: 2*n*m+(i+1)*n], X[i*n: (i+1)*n]))\n",
    "        grad[2*n*m+i*n:2*n*m+(i+1)*n] += np.dot(ten3, \n",
    "                                                 np.kron(X[i*n: (i+1)*n], X[n*m+i*n: n*m+(i+1)*n]))\n",
    "    return grad;\n",
    "\n",
    "\n",
    "\n",
    "def compute_tensor(X, Y, Z, n, m):\n",
    "    nx, ny, nz = n\n",
    "    ten = np.zeros(nx*ny*nz);\n",
    "    for i in range(m):\n",
    "        ten += np.kron(X[i], np.kron(Y[i], Z[i]))\n",
    "    return ten;\n",
    "\n",
    "def compute_nuc_approx(X, Y, Z, m):\n",
    "    val = 0;\n",
    "    for i in range(m):\n",
    "        val+= np.linalg.norm(X[i])*np.linalg.norm(Y[i])*np.linalg.norm(Z[i])\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_update_x(X, Y, Z, n, m, u, mu, entries_idx, entries, num_entries):\n",
    "    nx, ny, nz = n\n",
    "    num_sampl = num_entries+nx*m\n",
    "    num_feat = nx*m\n",
    "    M = np.zeros((num_sampl, num_feat))\n",
    "    B = np.zeros(num_sampl)\n",
    "    W = np.zeros(num_sampl)+1/(2*mu)\n",
    "    for i in range(nx*m):\n",
    "        M[i, i] = 1\n",
    "        W[i] = 1;\n",
    "    row = nx*m;\n",
    "    for t in range(num_entries):\n",
    "        xi = entries_idx[t, 0]\n",
    "        yi = entries_idx[t, 1]\n",
    "        zi = entries_idx[t, 2]\n",
    "        for j in range(m):\n",
    "            M[row, j*nx+xi]+= Y[j, yi]*Z[j, zi]\n",
    "        B[row] = entries[t]\n",
    "        row += 1\n",
    "    opt = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "    opt.fit(M, B, W)\n",
    "    X = opt.coef_.reshape((m, nx))\n",
    "    return X\n",
    "\n",
    "def reg_update_y(X, Y, Z, n, m, u, mu, entries_idx, entries, num_entries):\n",
    "    nx, ny, nz = n\n",
    "    num_sampl = num_entries+ny*m\n",
    "    num_feat = ny*m\n",
    "    M = np.zeros((num_sampl, num_feat))\n",
    "    B = np.zeros(num_sampl)\n",
    "    W = np.zeros(num_sampl)+1/(2*mu)\n",
    "    for i in range(ny*m):\n",
    "        M[i, i] = 1\n",
    "        W[i] = np.sum(Z[i//ny]**2)\n",
    "    row = ny*m;\n",
    "    for t in range(num_entries):\n",
    "        xi = entries_idx[t, 0]\n",
    "        yi = entries_idx[t, 1]\n",
    "        zi = entries_idx[t, 2]\n",
    "        for j in range(m):\n",
    "            M[row, j*ny+yi]+=X[j, xi]*Z[j, zi]\n",
    "        B[row] = entries[t]\n",
    "        row += 1\n",
    "    opt = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "    opt.fit(M, B, W)\n",
    "    Y = opt.coef_.reshape((m, ny))\n",
    "    return Y\n",
    "\n",
    "def reg_update_z(X, Y, Z, n, m, u, mu, entries_idx, entries, num_entries):\n",
    "    nx, ny, nz = n\n",
    "    num_sampl = num_entries+nz*m\n",
    "    num_feat = nz*m\n",
    "    M = np.zeros((num_sampl, num_feat))\n",
    "    B = np.zeros(num_sampl)\n",
    "    W = np.zeros(num_sampl)+1/(2*mu)\n",
    "    for i in range(nz*m):\n",
    "        M[i, i] = 1\n",
    "        W[i] = np.sum(Y[i//nz]**2)\n",
    "    row = nz*m;\n",
    "    for t in range(num_entries):\n",
    "        xi = entries_idx[t, 0]\n",
    "        yi = entries_idx[t, 1]\n",
    "        zi = entries_idx[t, 2]\n",
    "        for j in range(m):\n",
    "            M[row, j*nz+zi] += Y[j, yi]*X[j, xi]\n",
    "        B[row] = entries[t]\n",
    "        row += 1\n",
    "    opt = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "    opt.fit(M, B, W)\n",
    "    Z = opt.coef_.reshape((m, nz))\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_components(X, Y, Z, n, m):\n",
    "    nx, ny, nz = n\n",
    "    for i in range(m):\n",
    "        norm_x = np.sqrt(np.sqrt(np.sum(X[i]**2)))\n",
    "        norm_yz = np.sqrt(np.sqrt(np.sum(Y[i]**2)*np.sum(Z[i]**2)))\n",
    "        X[i] = X[i]*(norm_yz/norm_x)\n",
    "        Y[i] = Y[i]*np.sqrt(norm_x/norm_yz)\n",
    "        Z[i] = Z[i]*np.sqrt(norm_x/norm_yz)\n",
    "    return (X, Y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ten_entries2(tensor, n, num, seed = None):\n",
    "    nx, ny, nz = n;\n",
    "    step = 0;\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    entries = np.zeros((num, 3), dtype = 'int');\n",
    "    entries_val = np.zeros(num);\n",
    "    entries_xyz = {}\n",
    "    while (step<num):\n",
    "        i = np.random.randint(nx);\n",
    "        j = np.random.randint(ny);\n",
    "        k = np.random.randint(nz);\n",
    "        if (i not in entries_xyz.keys()):\n",
    "            entries_xyz[i] = {}\n",
    "        if (j not in entries_xyz[i].keys()):\n",
    "            entries_xyz[i][j] = {}\n",
    "        if (k not in entries_xyz[i][j].keys()):\n",
    "            val = tensor[i,j,k];\n",
    "            entries_xyz[i][j][k] = val;\n",
    "            entries[step, 0] = i\n",
    "            entries[step, 1] = j\n",
    "            entries[step, 2] = k\n",
    "            entries_val[step] = val\n",
    "            step+=1;\n",
    "    return entries, entries_val, entries_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_error_direct(X, Y, Z, n, m, tensor, num_trials = 1000):\n",
    "    nx, ny, nz = n\n",
    "    total_error = 0\n",
    "    total_norm = 0\n",
    "    for i in range(num_trials):\n",
    "        x = np.random.randint(nx)\n",
    "        y = np.random.randint(ny)\n",
    "        z = np.random.randint(nz)\n",
    "        prediction = 0\n",
    "        for j in range(m):\n",
    "            prediction += X[j, x] * Y[j, y] * Z[j, z]\n",
    "        true_val = tensor[x, y, z]\n",
    "        total_norm += np.square(true_val)\n",
    "        total_error += np.square(prediction - true_val)\n",
    "    return np.sqrt(total_error/total_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498.7578043994445\n"
     ]
    }
   ],
   "source": [
    "n = (150, 150, 150);\n",
    "nx, ny, nz = n\n",
    "m = 7;\n",
    "m1 = 9;\n",
    "num_entries = 20000\n",
    "np.random.seed(2021)\n",
    "X_true = np.random.rand(nx*m).reshape((m, nx));\n",
    "Y_true = np.random.rand(ny*m).reshape((m, ny));\n",
    "Z_true = np.random.rand(nz*m).reshape((m, nz));\n",
    "#Cor = np.random.rand(9*m*m).reshape((3*m, 3*m))\n",
    "#Cor = Cor/(100*np.linalg.norm(Cor))\n",
    "#Cor = Cor+np.identity(3*m);\n",
    "#X_true = np.dot(X_true.reshape(n, 3*m), Cor).reshape((3*n*m,))\n",
    "X_0 = np.random.rand(nx*m1).reshape((m1, nx));\n",
    "Y_0 = np.random.rand(ny*m1).reshape((m1, ny));\n",
    "Z_0 = np.random.rand(nz*m1).reshape((m1, nz));\n",
    "u = np.zeros(nx*ny*nz);\n",
    "mu = 1\n",
    "tensor = compute_tensor(X_true, Y_true, Z_true, n, m)\n",
    "a = compute_nuc_approx(X_true, Y_true, Z_true, m)\n",
    "print(a)\n",
    "\n",
    "entries_idx, entries, entries_xyz = generate_ten_entries2(tensor.reshape(n), n, num_entries, seed = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.988817930221558\n",
      "8535.39277390658\n",
      "F2 norm 442.638464\n",
      "eval_error_direct 0.245251\n",
      "16.501641035079956\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b7f650400dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.000001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mX_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_update_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mY_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_update_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mZ_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_update_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1e2a468da2fc>\u001b[0m in \u001b[0;36mreg_update_x\u001b[0;34m(X, Y, Z, n, m, u, mu, entries_idx, entries, num_entries)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_residues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingular_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_lwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlapack_lwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001b[0;32m-> 1211\u001b[0;31m                                                iwork, cond, False, False)\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# complex data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 lwork, rwork, iwork = _compute_lwork(lapack_lwork, m, n,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prog_1 = np.zeros(500)\n",
    "start = time.time()\n",
    "for mu in [0.1, 0.001, 0.0001, 0.00001, 0.000001]:\n",
    "    for step in range(20):\n",
    "        X_0 = reg_update_x(X_0, Y_0, Z_0, n, m1, u, mu, entries_idx, entries, num_entries)\n",
    "        Y_0 = reg_update_y(X_0, Y_0, Z_0, n, m1, u, mu, entries_idx, entries, num_entries)\n",
    "        Z_0 = reg_update_z(X_0, Y_0, Z_0, n, m1, u, mu, entries_idx, entries, num_entries)\n",
    "        X_0, Y_0, Z_0 = fix_components(X_0, Y_0, Z_0, n, m1)\n",
    "        if (step%5 == 0):\n",
    "            print(time.time() - start)\n",
    "            print(aul_f(X_0, Y_0, Z_0, n, m1, u, mu, tensor, entries = entries_xyz))\n",
    "            ten = compute_tensor(X_0, Y_0, Z_0, n, m1)\n",
    "            prog_1[step//5] = np.sqrt(np.sum((ten - tensor)**2))\n",
    "            print('F2 norm %f' % prog_1[step//5])\n",
    "            err = eval_error_direct(X_0, Y_0, Z_0, n, m1, tensor.reshape(n))\n",
    "            print('eval_error_direct %f' % err)\n",
    "            print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
