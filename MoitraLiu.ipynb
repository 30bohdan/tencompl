{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "4\n",
      "9000\n",
      "0\n",
      "Subspace Powering\n",
      "1.1637373209721766\n",
      "dir-err 1.000051\n",
      "1\n",
      "Subspace Powering\n",
      "1.2916902807030388\n",
      "dir-err 1.000067\n",
      "2\n",
      "Subspace Powering\n",
      "1.3389117485554642\n",
      "dir-err 0.999943\n",
      "3\n",
      "Subspace Powering\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4cc0aa1a96db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Subspace Powering\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_error\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                 \u001b[0mV_x2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubspace_altmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV_x2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_y2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_z2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m                 \u001b[0mV_y2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubspace_altmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV_y2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_z2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_x2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[0mV_z2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubspace_altmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV_z2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_x2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_y2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-4cc0aa1a96db>\u001b[0m in \u001b[0;36msubspace_altmin\u001b[1;34m(V_x, V_y, V_z, x_dict)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                     \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_coord\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV_z\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz_coord\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                     \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_coord\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz_coord\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes)\u001b[0m\n\u001b[0;32m   1391\u001b[0m     \u001b[0mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewaxes_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewshape_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m     \u001b[0mbt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewaxes_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewshape_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1394\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0molda\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moldb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#size of tensor\n",
    "n = 100\n",
    "#CP rank of tensor\n",
    "r = 4\n",
    "#number of observations\n",
    "num_samples = 9000\n",
    "p = min(float(num_samples/ (n*n*n)), 1)\n",
    "#Whether initialization is random or computed using initialization step\n",
    "randominit = False\n",
    "#Whether the underlying tensor will have correlated components\n",
    "correlated = False\n",
    "#Whether observations are exact or noisy\n",
    "noisy = False\n",
    "noise_size = 0.1\n",
    "#which algorithm to run\n",
    "#can be \"Matrix Alt Min, Tensor Powering, Subspace Powering, all\"\n",
    "which_alg = \"Subspace Powering\"\n",
    "#which_alg = \"Matrix Alt Min\"\n",
    "save_file = \"tensorpowering+noisy100_10_50000.csv\"\n",
    "#Number of different tensors to run on\n",
    "num_runs = 10\n",
    "#Number of iterations per run\n",
    "num_iter = 400\n",
    "#min error threshold\n",
    "threshold = 10**(-6)\n",
    "#generate random uncorrelated tensor\n",
    "def gen(n,r):\n",
    "    coeffs = np.ones(r)\n",
    "    x_vecs = np.random.normal(0,1,(r,n))\n",
    "    y_vecs = np.random.normal(0,1,(r,n))\n",
    "    z_vecs = np.random.normal(0,1,(r,n))\n",
    "    return (coeffs, x_vecs,y_vecs,z_vecs)\n",
    "\n",
    "#generate random correlated tensor\n",
    "def gen_biased(n,r):\n",
    "    coeffs = np.zeros(r)\n",
    "    x_vecs = np.zeros((r,n))\n",
    "    y_vecs = np.zeros((r,n))\n",
    "    z_vecs = np.zeros((r,n))\n",
    "    for i in range(r):\n",
    "        coeffs[i] = 0.5**i\n",
    "        if(i==0):\n",
    "            x_vecs[i] = np.sqrt(n) *normalize(np.random.normal(0,1,n))\n",
    "            y_vecs[i] = np.sqrt(n) *normalize(np.random.normal(0,1,n))\n",
    "            z_vecs[i] = np.sqrt(n) *normalize(np.random.normal(0,1,n))\n",
    "        else:\n",
    "            x_vecs[i] = np.sqrt(n) *normalize(np.random.normal(0,0.5,n) + x_vecs[0])\n",
    "            y_vecs[i] = np.sqrt(n) *normalize(np.random.normal(0,0.5,n) + y_vecs[0])\n",
    "            z_vecs[i] = np.sqrt(n) *normalize(np.random.normal(0,0.5,n) + z_vecs[0])\n",
    "    return (coeffs, x_vecs,y_vecs,z_vecs)\n",
    "#evaluate tensor given coordinates\n",
    "def T(i,j,k, coeffs, x_vecs, y_vecs, z_vecs):\n",
    "    ans = 0\n",
    "    for a in range(r):\n",
    "        ans += coeffs[a] * x_vecs[a][i] * y_vecs[a][j] * z_vecs[a][k]\n",
    "    return ans\n",
    "#sample observations, a is num_samples\n",
    "#returns 3 lists of coordinates\n",
    "def sample(a):\n",
    "    samples = np.random.choice(n**3, a, replace=False)\n",
    "    x_coords = samples%n\n",
    "    y_coords = (((samples - x_coords)/n)%n).astype(int)\n",
    "    z_coords = (((samples - n*y_coords - x_coords)/(n*n))%n).astype(int)\n",
    "    return (x_coords, y_coords, z_coords)\n",
    "#Given samples and tensor T, construct dictionary x_dict that stores the observations\n",
    "\n",
    "def fill(x_coords, y_coords, z_coords, coeffs, x_vecs, y_vecs, z_vecs, x_dict):\n",
    "    num_samples = x_coords.size\n",
    "    for i in range(num_samples):\n",
    "    #For x_dict coordinates are in order x,y,z\n",
    "        if(x_coords[i] in x_dict.keys()):\n",
    "            if(y_coords[i] in x_dict[x_coords[i]].keys()):\n",
    "                if(z_coords[i] in x_dict[x_coords[i]][y_coords[i]].keys()):\n",
    "                    pass\n",
    "                else:\n",
    "                    x_dict[x_coords[i]][y_coords[i]][z_coords[i]] = T(x_coords[i] , \n",
    "                                                            y_coords[i] , z_coords[i], coeffs,x_vecs, y_vecs, z_vecs)\n",
    "            else:\n",
    "                x_dict[x_coords[i]][y_coords[i]] = {}\n",
    "                x_dict[x_coords[i]][y_coords[i]][z_coords[i]]= T(x_coords[i] , \n",
    "                                                                 y_coords[i] , z_coords[i], coeffs, x_vecs, y_vecs, z_vecs)\n",
    "        else:\n",
    "            x_dict[x_coords[i]] = {}\n",
    "            x_dict[x_coords[i]][y_coords[i]] = {}\n",
    "            x_dict[x_coords[i]][y_coords[i]][z_coords[i]] = T(x_coords[i] , \n",
    "                                                            y_coords[i] , z_coords[i], coeffs, x_vecs, y_vecs, z_vecs)\n",
    "#normalize vector\n",
    "def normalize(v):\n",
    "    u = v/np.linalg.norm(v)\n",
    "    return u\n",
    "#given rxn array, output orthonormal basis\n",
    "def orthonormalize(V):\n",
    "    a = len(V)\n",
    "    b = len(V[0])\n",
    "    for i in range(a):\n",
    "        for j in range(i):\n",
    "            V[i] = V[i] - np.dot(V[i],V[j])*V[j]\n",
    "        V[i] = normalize(V[i])\n",
    "    return V\n",
    "#implicit sparse matrix multiplication where M is stored as a dictionary\n",
    "def mult(M,v):\n",
    "    u = np.zeros(n)\n",
    "    for coord1 in M.keys():\n",
    "        for coord2 in M[coord1].keys():\n",
    "            u[coord1] += M[coord1][coord2] * v[coord2]\n",
    "    return u\n",
    "#Compute initial subspace estimates\n",
    "def initialization(x_dict):\n",
    "    M_x = np.zeros((n,n))\n",
    "    for x in x_dict.keys():\n",
    "        for y in x_dict[x].keys():\n",
    "            for z1 in x_dict[x][y].keys():\n",
    "                for z2 in x_dict[x][y].keys():\n",
    "                    val = x_dict[x][y][z1] * x_dict[x][y][z2]\n",
    "                    if(z1 == z2):\n",
    "                        val = val/p\n",
    "                    else:\n",
    "                        val = val/(p*p)\n",
    "                    M_x[z1][z2] += val\n",
    "    svd = TruncatedSVD(n_components=r)\n",
    "    svd.fit(M_x)\n",
    "    return(svd.components_)\n",
    "#Unfold and perform matrix completion via altmin\n",
    "def matrix_altmin(V_x, V_yz):\n",
    "    #Solve for next iteration of x\n",
    "    lsq_solution = []\n",
    "    for i in range(n):\n",
    "        features = []\n",
    "        target = []\n",
    "        for y_coord in x_dict[i].keys():\n",
    "            for z_coord in x_dict[i][y_coord].keys():\n",
    "                features.append(V_yz[n*y_coord + z_coord])\n",
    "                target.append(x_dict[i][y_coord][z_coord])\n",
    "        features = np.array(features)\n",
    "        target = np.array(target)\n",
    "        reg = LinearRegression(fit_intercept = False).fit(features, target)\n",
    "        lsq_solution.append(reg.coef_)\n",
    "    x_solution = np.array(lsq_solution)\n",
    "    #Solve for next iteration of yz\n",
    "    lsq_solution2 = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            features = []\n",
    "            target = []\n",
    "            if i in y_dict.keys() and j in y_dict[i].keys():\n",
    "                for x_coord in y_dict[i][j].keys():\n",
    "                    features.append(x_solution[x_coord])\n",
    "                    target.append(y_dict[i][j][x_coord])\n",
    "                features = np.array(features)\n",
    "                target = np.array(target)\n",
    "                reg = LinearRegression(fit_intercept = False).fit(features, target)\n",
    "                lsq_solution2.append(reg.coef_)\n",
    "            else:\n",
    "                lsq_solution2.append(np.zeros(r))\n",
    "    newV_x = x_solution\n",
    "    newV_yz =np.array(lsq_solution2)\n",
    "    return(newV_x, newV_yz)\n",
    "#Normalized MSE for unfolded matrix completion\n",
    "def eval_error_matrix(V_x,V_yz):\n",
    "    #take random sample of entries to speed up evaluation\n",
    "    num_trials = 1000\n",
    "    total_error = 0\n",
    "    total_norm = 0\n",
    "    for i in range(num_trials):\n",
    "        x = np.random.randint(n)\n",
    "        y = np.random.randint(n)\n",
    "        z = np.random.randint(n)\n",
    "        prediction = 0\n",
    "        for j in range(r):\n",
    "            prediction += V_x[x][j] * V_yz[n * y + z][j]\n",
    "        true_val = T(x,y,z, coeffs, x_vecs,y_vecs, z_vecs)\n",
    "        total_norm += np.square(true_val)\n",
    "        total_error += np.square(prediction - true_val)\n",
    "    return np.sqrt(total_error/total_norm)\n",
    "#altmin for naive tensor powering\n",
    "def power_altmin(V_x, V_y, V_z , x_dict):\n",
    "    lsq_solution = []\n",
    "    for i in range(n):\n",
    "        features = []\n",
    "        target = []\n",
    "        for y_coord in x_dict[i].keys():\n",
    "            for z_coord in x_dict[i][y_coord].keys():\n",
    "                #subsample to speed up and get \"unstuck\"\n",
    "                check = np.random.randint(2)\n",
    "                if(check == 0):\n",
    "                    features.append(np.multiply(V_y[y_coord], V_z[z_coord]))\n",
    "                    target.append(x_dict[i][y_coord][z_coord])\n",
    "        features = np.array(features)\n",
    "        target = np.array(target)\n",
    "        reg = LinearRegression(fit_intercept = False).fit(features, target)\n",
    "        lsq_solution.append(reg.coef_)\n",
    "    lsq_solution = np.array(lsq_solution)\n",
    "    return(lsq_solution)\n",
    "\n",
    "#Normalized MSE for naive tensor powering\n",
    "def eval_error_direct(V_x,V_y,V_z, x_dict):\n",
    "    num_trials = 1000\n",
    "    total_error = 0\n",
    "    total_norm = 0\n",
    "    for i in range(num_trials):\n",
    "        x = np.random.randint(n)\n",
    "        y = np.random.randint(n)\n",
    "        z = np.random.randint(n)\n",
    "        prediction = 0\n",
    "        for j in range(r):\n",
    "            prediction += V_x[x][j] * V_y[y][j] * V_z[z][j]\n",
    "        true_val = T(x,y,z, coeffs, x_vecs,y_vecs, z_vecs)\n",
    "        total_norm += np.square(true_val)\n",
    "        total_error += np.square(prediction - true_val)\n",
    "    return np.sqrt(total_error/total_norm)\n",
    "#altmin for our algorithm\n",
    "def subspace_altmin(V_x, V_y, V_z , x_dict):\n",
    "    lsq_solution = []\n",
    "    for i in range(n):\n",
    "        features = []\n",
    "        target = []\n",
    "        for y_coord in x_dict[i].keys():\n",
    "            for z_coord in x_dict[i][y_coord].keys():\n",
    "                #subsample to speed up and get \"unstuck\"\n",
    "                check = np.random.randint(2)\n",
    "                if(check == 0):\n",
    "                    features.append(np.tensordot(V_y[y_coord], V_z[z_coord] , axes = 0).flatten())\n",
    "                    target.append(x_dict[i][y_coord][z_coord])\n",
    "        features = np.array(features)\n",
    "        target = np.array(target)\n",
    "        np.savetxt(save_file, features, delimiter=\",\")\n",
    "        reg = LinearRegression(fit_intercept = False).fit(features,target)\n",
    "        lsq_solution.append(reg.coef_)\n",
    "    lsq_solution = np.transpose(np.array(lsq_solution))\n",
    "    svd = TruncatedSVD(n_components=r)\n",
    "    svd.fit(lsq_solution)\n",
    "    return(np.transpose(svd.components_))\n",
    "    \n",
    "#Normalized MSE for our algorithm\n",
    "def eval_error_subspace(V_x,V_y,V_z, x_dict):\n",
    "    features = []\n",
    "    target = []\n",
    "    #Find coefficients in V_x x V_y x V_z basis\n",
    "    for x_coord in x_dict.keys():\n",
    "        for y_coord in x_dict[x_coord].keys():\n",
    "            for z_coord in x_dict[x_coord][y_coord].keys():\n",
    "                #speed up by using less entries\n",
    "                check = np.random.randint(10)\n",
    "                if(check == 0):\n",
    "                    target.append(x_dict[x_coord][y_coord][z_coord])\n",
    "                    part = np.tensordot(V_x[x_coord], V_y[y_coord], axes = 0).flatten()\n",
    "                    full = np.tensordot(part, V_z[z_coord],axes = 0).flatten()\n",
    "                    features.append(full)\n",
    "    features = np.array(features)\n",
    "    target = np.array(target)\n",
    "    reg = LinearRegression(fit_intercept = False).fit(features, target)\n",
    "    solution_coeffs = reg.coef_\n",
    "    #print(reg.score(features, target))\n",
    "    #print(solution_coeffs)\n",
    "    #Evaluate RMS error\n",
    "    num_trials = 1000\n",
    "    total_error = 0\n",
    "    total_norm = 0\n",
    "    for i in range(num_trials):\n",
    "        x = np.random.randint(n)\n",
    "        y = np.random.randint(n)\n",
    "        z = np.random.randint(n)\n",
    "        part = np.tensordot(V_x[x], V_y[y], axes = 0).flatten()\n",
    "        feature = np.tensordot(part, V_z[z], axes = 0).flatten()\n",
    "        prediction = np.dot(feature, solution_coeffs)\n",
    "        true_val = T(x,y,z, coeffs, x_vecs,y_vecs, z_vecs)\n",
    "        total_norm += np.square(true_val)\n",
    "        total_error += np.square(prediction - true_val)\n",
    "    return np.sqrt(total_error/total_norm)\n",
    "#Keep track of errors for all runs\n",
    "\n",
    "all_errors = []\n",
    "for run in range(num_runs):\n",
    "    #store error over time for this run\n",
    "    error = []\n",
    "    curr_error = 1.0\n",
    "    #Construct random tensor\n",
    "    if(correlated):\n",
    "        coeffs, x_vecs,y_vecs,z_vecs = gen_biased(n,r)\n",
    "    else:\n",
    "        coeffs, x_vecs,y_vecs,z_vecs = gen(n,r)\n",
    "    x_coords,y_coords,z_coords = sample(num_samples)\n",
    "    #x_dict,y_dict, z_dict each stores all observed entries\n",
    "    #x_dict has coordinates in order x,y,z\n",
    "    #y_dict has coordinates in order y,z,x\n",
    "    #z_dict has coordinates in order z,x,y\n",
    "    x_dict = {}\n",
    "    y_dict = {}\n",
    "    z_dict = {}\n",
    "    fill(x_coords, y_coords, z_coords, coeffs, x_vecs, y_vecs, z_vecs, x_dict)\n",
    "    fill(y_coords, z_coords, x_coords, coeffs, y_vecs, z_vecs, x_vecs, y_dict)\n",
    "    fill(z_coords, x_coords, y_coords, coeffs, z_vecs, x_vecs, y_vecs, z_dict)\n",
    "    #Add Noise\n",
    "    if(noisy):\n",
    "        for x_coord in x_dict.keys():\n",
    "            for y_coord in x_dict[x_coord].keys():\n",
    "                for z_coord in x_dict[x_coord][y_coord].keys():\n",
    "                    x_dict[x_coord][y_coord][z_coord] += np.random.normal(0,noise_size)\n",
    "                    y_dict[y_coord][z_coord][x_coord] += np.random.normal(0,noise_size)\n",
    "                    z_dict[z_coord][x_coord][y_coord] += np.random.normal(0,noise_size)\n",
    "    #Initialization\n",
    "    if(randominit):\n",
    "        V_x = np.random.normal(0,1,(r,n))\n",
    "        V_y = np.random.normal(0,1,(r,n))\n",
    "        V_z = np.random.normal(0,1,(r,n))\n",
    "        V_x = orthonormalize(V_x)\n",
    "        V_y = orthonormalize(V_y)\n",
    "        V_z = orthonormalize(V_z)\n",
    "        V_x = np.transpose(V_x)\n",
    "        V_y = np.transpose(V_y)\n",
    "        V_z = np.transpose(V_z)\n",
    "    else:\n",
    "        V_x = np.transpose(initialization(y_dict))\n",
    "        V_y = np.transpose(initialization(z_dict))\n",
    "        V_z = np.transpose(initialization(x_dict))\n",
    "    #For unfolding and matrix completion\n",
    "    V_xmat = np.random.normal(0,1, (r,n))\n",
    "    V_yzmat = np.random.normal(0,1, (r, n*n))\n",
    "    V_xmat = orthonormalize(V_xmat)\n",
    "    V_yzmat = orthonormalize(V_yzmat)\n",
    "    V_xmat = np.transpose(V_xmat)\n",
    "    V_yzmat = np.transpose(V_yzmat)\n",
    "    V_x2 = np.copy(V_x)\n",
    "    V_y2 = np.copy(V_y)\n",
    "    V_z2 = np.copy(V_z)\n",
    "    print(n)\n",
    "    print(r)\n",
    "    print(num_samples)\n",
    "    #AltMin Steps\n",
    "    for i in range(num_iter):\n",
    "        print(i)\n",
    "        if(which_alg == \"Matrix Alt Min\" or which_alg == \"all\"):\n",
    "            print(\"Matrix Alt Min\")\n",
    "            V_xmat, V_yzmat = matrix_altmin(V_xmat, V_yzmat)\n",
    "            curr_error = eval_error_matrix(V_xmat, V_yzmat)\n",
    "            print(curr_error)\n",
    "            error.append(curr_error)\n",
    "        if(which_alg == \"Tensor Powering\" or which_alg == \"all\"):\n",
    "            print(\"Tensor Powering\")\n",
    "            if(curr_error > threshold):\n",
    "                V_x = power_altmin(V_x,V_y,V_z, x_dict)\n",
    "                V_y = power_altmin(V_y,V_z,V_x, y_dict)\n",
    "                V_z = power_altmin(V_z,V_x,V_y, z_dict)\n",
    "                curr_error = eval_error_direct(V_x,V_y,V_z,x_dict)\n",
    "            print(curr_error)\n",
    "            error.append(curr_error)\n",
    "        if(which_alg == \"Subspace Powering\" or which_alg == \"all\"):\n",
    "            print(\"Subspace Powering\")\n",
    "            if(curr_error > threshold):\n",
    "                V_x2 = subspace_altmin(V_x2,V_y2,V_z2, x_dict)\n",
    "                V_y2 = subspace_altmin(V_y2,V_z2,V_x2, y_dict)\n",
    "                V_z2 = subspace_altmin(V_z2,V_x2,V_y2, z_dict)\n",
    "                curr_error_dir = eval_error_direct(V_x,V_y,V_z,x_dict)\n",
    "                curr_error = eval_error_subspace(V_x2,V_y2,V_z2, x_dict)\n",
    "            print(curr_error)\n",
    "            print('dir-err %f' % curr_error_dir)\n",
    "            error.append(curr_error)\n",
    "    all_errors.append(error)\n",
    "    to_save = np.transpose(np.array(all_errors))\n",
    "    avg_errors = np.mean(to_save, axis = 0)\n",
    "    np.savetxt(save_file, to_save, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moitra_liu as ml_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc = ml_ten.ML_completion((100, 100, 100), 10, 30000, \"save_file.txt\", randominit = False, num_iter = 50, num_runs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n",
      "10\n",
      "30000\n",
      "0\n",
      "Subspace Powering\n",
      "1.4098299530193015\n",
      "1\n",
      "Subspace Powering\n",
      "1.7106350245109356\n",
      "2\n",
      "Subspace Powering\n",
      "2.106892557398388\n",
      "3\n",
      "Subspace Powering\n",
      "1.8106616391317802\n",
      "4\n",
      "Subspace Powering\n",
      "2.215094941697373\n",
      "5\n",
      "Subspace Powering\n",
      "1.9051201513638054\n",
      "6\n",
      "Subspace Powering\n",
      "1.864150719224102\n",
      "7\n",
      "Subspace Powering\n",
      "1.8844871548593645\n",
      "8\n",
      "Subspace Powering\n",
      "2.08308958802064\n",
      "9\n",
      "Subspace Powering\n",
      "1.7453020864022295\n",
      "10\n",
      "Subspace Powering\n",
      "1.97692919412061\n",
      "11\n",
      "Subspace Powering\n",
      "2.3122455874958785\n",
      "12\n",
      "Subspace Powering\n",
      "2.117540130723159\n",
      "13\n",
      "Subspace Powering\n",
      "2.3266413371302725\n",
      "14\n",
      "Subspace Powering\n",
      "1.9997828099731758\n",
      "15\n",
      "Subspace Powering\n",
      "1.8611923704209565\n",
      "16\n",
      "Subspace Powering\n",
      "2.43852295518862\n",
      "17\n",
      "Subspace Powering\n",
      "2.012177205886153\n",
      "18\n",
      "Subspace Powering\n",
      "2.289445495277841\n",
      "19\n",
      "Subspace Powering\n",
      "1.8607236954078266\n",
      "20\n",
      "Subspace Powering\n",
      "2.858324563688062\n",
      "21\n",
      "Subspace Powering\n",
      "1.9149689519776498\n",
      "22\n",
      "Subspace Powering\n",
      "2.1232688344540183\n",
      "23\n",
      "Subspace Powering\n",
      "1.9950219139833472\n",
      "24\n",
      "Subspace Powering\n",
      "2.277027946009536\n",
      "25\n",
      "Subspace Powering\n",
      "2.3732099153845425\n",
      "26\n",
      "Subspace Powering\n",
      "2.182054182726265\n",
      "27\n",
      "Subspace Powering\n",
      "1.78838697111645\n",
      "28\n",
      "Subspace Powering\n",
      "2.235531792934314\n",
      "29\n",
      "Subspace Powering\n",
      "2.0410519045598825\n",
      "30\n",
      "Subspace Powering\n",
      "2.106328164689777\n",
      "31\n",
      "Subspace Powering\n",
      "1.7251135819702472\n",
      "32\n",
      "Subspace Powering\n",
      "2.0926032974211446\n",
      "33\n",
      "Subspace Powering\n",
      "1.9015814425933744\n",
      "34\n",
      "Subspace Powering\n",
      "2.0732909588095523\n",
      "35\n",
      "Subspace Powering\n",
      "1.9546917727669555\n",
      "36\n",
      "Subspace Powering\n",
      "1.9568176902612942\n",
      "37\n",
      "Subspace Powering\n",
      "2.014575229398335\n",
      "38\n",
      "Subspace Powering\n",
      "2.142504583727816\n",
      "39\n",
      "Subspace Powering\n",
      "2.017650156290751\n",
      "40\n",
      "Subspace Powering\n",
      "2.140206069424883\n",
      "41\n",
      "Subspace Powering\n",
      "1.756932739905259\n",
      "42\n",
      "Subspace Powering\n",
      "1.8458437779502337\n",
      "43\n",
      "Subspace Powering\n",
      "2.0500488754672888\n",
      "44\n",
      "Subspace Powering\n",
      "2.191176389846243\n",
      "45\n",
      "Subspace Powering\n",
      "1.8800610507039965\n",
      "46\n",
      "Subspace Powering\n",
      "1.8954479390152366\n",
      "47\n",
      "Subspace Powering\n",
      "1.6055137838314812\n",
      "48\n",
      "Subspace Powering\n",
      "2.013822990105607\n",
      "49\n",
      "Subspace Powering\n",
      "1.970060800458939\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_errors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b104350f9bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\disk-copy\\bohdan\\coursov\\2021\\ten-compl-opt\\experiments\\moitra_liu.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;31m#print('dir-err %f' % curr_error_dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         \u001b[0mall_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m         \u001b[0mto_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_errors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[0mavg_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_save\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_errors' is not defined"
     ]
    }
   ],
   "source": [
    "mlc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
